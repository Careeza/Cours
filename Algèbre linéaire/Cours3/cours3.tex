\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[a4paper, total={6in, 8in}]{geometry}
\usepackage{setspace}

\newcommand\tab[1][1cm]{\hspace*{#1}}
\onehalfspacing
\author{Frederic Becerril}

\begin{document}

\part*{Chapitre 2: Orthogonalité dans $\mathbb{R}^n$}

On notera $x . y$ ou $<x | y>$ le produit scalaire usuel de $\mathbb{R}^n$ \\
Pour mémoire, si $(E, f(,))$ est un espace euclidien de dimension n, alors E admet une base orthonormée $\{u_1, \dots, u_n\} = U$ et on a un isomorphisme:
$$\varphi : E \rightarrow \mathbb{R}$$
$$a = \alpha_1 u_1 + \dots + \alpha_n u_n \longmapsto
\left(
    \begin{array}{ll}
        \alpha_1 \\
        \vdots \\
        \alpha_n \\
    \end{array}
\right)
$$
$$\mbox{On a alors que si (a, b) } \in E^2 \mbox{ et } \varphi(a) =
\begin{pmatrix}
    \alpha_1 \\
    \vdots \\
    \alpha_n \\
\end{pmatrix}
\;\;\varphi(b) =
\begin{pmatrix}
    \beta_1 \\
    \vdots \\
    \beta_n \\
\end{pmatrix}
$$
$$f(a, b) = 
\begin{pmatrix}
    \alpha_1 \\
    \vdots \\
    \alpha_n \\
\end{pmatrix}
\circ
\begin{pmatrix}
    \beta_1 \\
    \vdots \\
    \beta_n \\
\end{pmatrix}
$$

Dans tout espace euclidien est isomorphe à $\mathbb{R}^n$ muni du produit scalaire usuel. \\
Cela signifie qu'on peut se contenter de travailler dans $\mathbb{R}^n$ mais aussi que tout 
ce qui est énoncé s'applique dans n'importe quel espace euclidien

\section{\underline{Retour sur les bases orthogonales et orthonormées}}

\subsection{\underline{Coordonnées:}}

\paragraph{\underline{Proposition:}} Soit $B = \{e_1, \dots, e_n\}$ une base orthogonale
de $(\mathbb{R}^n, <|>)$ (ou $(E, <|>)$) alors:
$$\forall x \in \mathbb{R}^n \tab x = \frac{<x|e_1>}{<e_1|e_1>}e_1 + \dots + \frac{<x|e_n>}{<e_n|e_n>}e_n$$
$$\tab[3.6cm] = \sum_{k=1}^n \frac{<x|e_k>}{<e_k|e_k>}e_k = \sum_{k=1}^n \frac{<x|e_k>}{||e_k||^2}e_k$$

\paragraph{\underline{Remarque:}} Dnas une base quelconque $\mathbb{R}^n$ un telle décomposition n'est pas si facile ! On écrit :
$P = (e_1 \vdots \dots \vdots e_n)
\mbox{, } x = \alpha_1 e_1 + \dots + \alpha_n e_n
\mbox{ et } x =
\begin{pmatrix}
    x_1 \\
    \vdots \\
    x_n \\    
\end{pmatrix}
$ revient à résoudre $$P \circ \begin{pmatrix}
    \alpha_1 \\
    \vdots \\
    \alpha_n \\
\end{pmatrix} = \begin{pmatrix}
    x_1 \\
    \vdots \\
    x_n \\
\end{pmatrix}$$

\paragraph{\underline{Preuve:}} Puisque $B = \{e_1, \dots, e_n\}$ est une base, on sait qu'il
existe, pour $x \in \mathbb{R}^n$ fixé, un unique n-uplet $(\alpha_1, \dots, \alpha_n)$ tel que
$$x = \alpha_1 e_1 + \dots + \alpha_n e_n = \sum_{i = 1}^n \alpha_i e_i$$
pour $1 \leq k \leq n$ on a alors
$$<x | e_k> = <\sum_{i=1}^n \alpha_i e_i | e_k > = \sum_{i=1}^n \alpha_i <e_i | e_k>$$
d'où
$$<x | e_k> = \alpha_k <e_k | e_k> \mbox{ et donc }$$
$$\alpha_k = \frac{<x|e_k>}{<e_k|e_k>} = \frac{<x|e_k>}{||e_k||^2}$$

\paragraph{\underline{Corollaire 1:}} Soit B une base orthonormée $B = \{u_1, \dots, u_n\}$ de $\mathbb{R}^n$, alors:
$$\forall x \in \mathbb{R}^n \tab[0.5cm] x = \sum_{k=1}^n <x | u_k> u_k$$

\paragraph{\underline{Corollaire 2:}} Si F est un sev de $\mathbb{R}^n$ et F = $Vect\{u_1, \dots, u_n\}$ où $\{u_1, \dots, u_n\}$ est une famille orthonormée, alors :
$$\forall x \in F \tab[0.5cm] x = \sum_{k=1}^n <x | u_k> u_k$$

On commence à voir ici l'intérêt des bases orthonormées mais comment en construire, par exemple dans un sous espace vectoriel ?

\subsection{\underline{Le procédé de Gram-Schmidt:}}

\paragraph{\underline{Théorème:}} Soit $\{x_1, \dots, x_p\}$ une base d'un sev non nul W de $\mathbb{R}^n \; (1 \leq k \leq n)$ : On définit successivement
$$v_1 = x_1 \tab \mbox{et} \tab u_1 = \frac{v_1}{||v_1||}$$
$$v_2 = x_2 - \frac{<x_2|v_1>}{<v_1|v_1>}v_1 \tab \mbox{et} \tab u_2 = \frac{v_2}{||v_2||}$$
$$\vdots$$
$$v_p = x_p - \frac{<x_p|v_1>}{<v_1|v_1>}v_1 - \frac{<x_p|v_2>}{<v_2|v_2>}v_2 - \dots - \frac{<x_p|v_{p-1}>}{<v_{p-1}|v_{p-1}>}v_{p-1}$$
$$\mbox{et } u_p = \frac{v_p}{||v_p||}$$

Alors $\{v_1, \dots, v_p\}$ est une base orthogonale de W.\\
\tab[1.4cm] $\{u_1, \dots, u_p\}$ est une base orthonormé de W et\\
$\forall 1 \leq k \leq p \tab Vect\{u_1, \dots, u_k\} = Vect\{v_1, \dots, v_k\} = Vect\{x_1, \dots, x_k\}$

\paragraph{\underline{Remarque:}} On sait aussi que \\
$v_k = x_k - <x_k|u_1>u_1 - \dots - <x_k|u_{k-1}>u_{k-1}$ et $u_k = \frac{v_k}{||v_k||}$ 

\begin{itemize}
    \item Partant d'une base quelconque de W, on construit explicitement une base orthonormée
    \item Ce théorème est valide dans n'importe quel espace euclidien. Ceci fournit une seconde preuve de l'existence de bases orthonormée dans un espace euclidien
\end{itemize}

\paragraph{\underline{Démonstration:}} Montrons d'abord par récurrence finie\\
$H_k, \{u_1, \dots, u_k\} \mbox{ est une base orthogonale de } W_k = Vect\{x_1, \dots, x_k\} pour tout 1 \leq k \leq p$

\begin{itemize}
    \item Pour $k = 1 \tab[0.5cm] v_1 = x_1 \neq 0 donc Vect\{v_1\} = Vect\{x_1\} = W_1 et v_1 est une base de W_1$ \tab[0.5cm] \underline{$H_1$ vrai}
    \item Supposons pour $1 \leq k < p$, qu'on a construit $\{v_1, \dots, v_k\}$ \\ base orthogonale de $W_k = Vect\{x_1, \dots, x_k\}$ (et donc = $Vect\{v_1, \dots, v_k\}$)\\
On pose $v_{k+1} = x_{k + 1} - \sum_{j=1}^k \frac{<x_{k+1} | v_j>}{<v_j | v_j>}v_j$ \\
$v_{k+1}$ n'est pas nul car sinon $x_{k+1} \in W_k$ or c'est impossible\\
Si $v_{k+1} \in W_{k+1}$ (ainsi que $v_1, \dots, v_k$)\\
$<v_{k+1} | v_l> = <x_{k+1} | v_l> - \sum_{j = 1}^k \frac{<x_{k+1} | v_j>}{<v_j | v_j>}<v_j | v_l>$\\
$\tab[1.8cm] = <x_{k+1} | v_l> - \frac{<x_{k+1} | v_l>}{<v_l | v_l>}<v_l|v_l>$\\
$\tab[1.8cm] = 0$\\
La famille ${v_1, \dots, v_k, v_{k+1}}$ est une famille orthogonale de vecteurs non nul. \\
$Vect\{v_1, \dots, v_{k+1}\} \subset W_{k+1} \mbox{ de dim } k + 1$ \\
$Vect\{v_1, \dots, v_{k+1}\}$ est aussi de dimension k + 1 car libre\\

On en déduit donc que $\{v_1, \dots, v_{k+1}\}$ est une base orthogonale de $W_{k+1}$

\item On conclut par principe de récurrence, car pour tout $1 \leq k < p \tab H_k \Rightarrow H_{k+1}$
\end{itemize}

Le passage à la base orthonormée est une évidence.

\paragraph{\underline{Exemple:}}
Dans $\mathbb{R}^3$ on pose 
$x_1 = \begin{pmatrix}
    1\\
    1\\
    1\\
\end{pmatrix} \tab[0.5cm]
x_2 = \begin{pmatrix}
    0\\
    1\\
    1\\
\end{pmatrix} \tab[0.5cm]
x_3 = \begin{pmatrix}
    0\\
    0\\
    1\\
\end{pmatrix}$\\
$V_1 = \begin{pmatrix}
    1\\
    1\\
    1\\
\end{pmatrix} \tab[0.5cm]
||v_1||^2 = <v_1|v_1> = 3 \mbox{ donc } u_1 = \frac{1}{\sqrt{3}}\begin{pmatrix}
    1\\
    1\\
    1\\
\end{pmatrix}$\\
$v_2 = \begin{pmatrix}
    0\\
    1\\
    1\\
\end{pmatrix} - \frac{<x_2|v_1>}{<v_1|v_1>}v_1 = \begin{pmatrix}
    0\\
    1\\
    1\\
\end{pmatrix} - \frac{2}{3} \begin{pmatrix}
    1\\
    1\\
    1\\
\end{pmatrix}$\\
$v_2 = \begin{pmatrix}
    \frac{-2}{3}\\
    \frac{1}{3}\\
    \frac{1}{3}\\
\end{pmatrix} \tab[0.5cm]
||v_2||^2 = <v_2 | v_2> = \frac{2}{3} \tab[0.5cm] u_2 = \frac{1}{\sqrt{\frac{2}{3}}} \begin{pmatrix}
    \frac{-2}{3}\\
    \frac{1}{3}\\
    \frac{1}{3}\\
\end{pmatrix}
= \begin{pmatrix}
    -\frac{\sqrt{2}}{\sqrt{3}}\\
    \frac{1}{\sqrt{6}}\\
    \frac{1}{\sqrt{6}}\\
\end{pmatrix}$\\
$v_3 = \begin{pmatrix}
    0\\
    0\\
    1\\
\end{pmatrix} - \frac{<x_3|v_1>}{<v_1|v_1>}v_1 - \frac{<x_3|v_2>}{<v_2|v_2>}v_2$\\
$v_3 = \begin{pmatrix}
    0\\
    0\\
    1\\
\end{pmatrix} - \frac{1}{3} \begin{pmatrix}
    1\\
    1\\
    1\\
\end{pmatrix} - \frac{1}{2} \begin{pmatrix}
    \frac{-2}{3}\\
    \frac{1}{3}\\
    \frac{1}{3}\\
\end{pmatrix}$\\
$v_3 = \begin{pmatrix}
    0\\
    0\\
    1\\
\end{pmatrix} + \begin{pmatrix}
    -\frac{1}{3}\\
    -\frac{1}{3}\\
    -\frac{1}{3}\\
\end{pmatrix} \begin{pmatrix}
    \frac{1}{3}\\
    -\frac{1}{6}\\
    -\frac{1}{6}\\
\end{pmatrix}
= \begin{pmatrix}
    0\\
    -\frac{1}{2}\\
    \frac{1}{2}\\
\end{pmatrix}
$\\
$||v_3||^2 = <v_3 | v_3> = \frac{1}{2} \tab u_3 = \begin{pmatrix}
    0\\
    -\frac{1}{\sqrt{2}}\\
    \frac{1}{\sqrt{2}}\\
\end{pmatrix}$

\end{document}